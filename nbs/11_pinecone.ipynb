{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pinecone\n",
    "\n",
    "> Pinecone is a vector database. You can query it using vectors to find semantically similar other vectors quickly. Semantic search using vector databases is often used to locate relevant text that is added to llm prompts, enabling long term 'memory'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def foo(): pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import os, \n",
    "import jarvis.secrets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "PINECONE_API_KEY = os.environ[\"PINECONE_API_KEY\"]\n",
    "PINECONE_ENV = os.environ[\"PINECONE_ENV\"]\n",
    "PINECONE_TEST_NAMESPACE = os.environ[\"PINECONE_TEST_NAMESPACE\"]\n",
    "OPENAI_API_KEY = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_LENGTH = 1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import TextLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 549, which is longer than the specified 500\n",
      "Created a chunk of size 667, which is longer than the specified 500\n",
      "Created a chunk of size 767, which is longer than the specified 500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "loader = TextLoader('../examples/data/pg_essay_beyond_smart.txt')\n",
    "documents = loader.load()\n",
    "text_splitter = CharacterTextSplitter(chunk_size=500, chunk_overlap=100)\n",
    "docs = text_splitter.split_documents(documents)[:10] #limit length to 10 for this example.\n",
    "print(len(docs))\n",
    "\n",
    "embeddings = OpenAIEmbeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/rapids/lib/python3.9/site-packages/pinecone/index.py:4: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import pinecone "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
    "    environment=PINECONE_ENV  # next to api key in console\n",
    ")\n",
    "\n",
    "index_name = \"pinecone-index-1\"\n",
    "\n",
    "docsearch = Pinecone.from_documents(docs, embeddings, index_name=index_name, namespace=PINECONE_TEST_NAMESPACE)\n",
    "\n",
    "query = \"What are the keys to being smart?\"\n",
    "docs = docsearch.similarity_search(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why do so many smart people fail to discover anything new? Viewed from that direction, the question seems a rather depressing one. But there's another way to look at it that's not just more optimistic, but more interesting as well. Clearly intelligence is not the only ingredient in having new ideas. What are the other ingredients? Are they things we could cultivate?\n"
     ]
    }
   ],
   "source": [
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENV)\n",
    "index = pinecone.Index(\"pinecone-index-1\")\n",
    "\n",
    "query_response = index.query(\n",
    "    namespace=PINECONE_TEST_NAMESPACE,\n",
    "    top_k=10,\n",
    "    include_values=True,\n",
    "    include_metadata=True,\n",
    "    vector=[0.1]*1536,\n",
    "    filter=None\n",
    ")\n",
    "print(len(query_response.get('matches',[])))\n",
    "# query_response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pinecone query and response**\n",
    "```\n",
    "query_response = index.query(\n",
    "    namespace='',\n",
    "    top_k=10,\n",
    "    include_values=True,\n",
    "    include_metadata=True,\n",
    "    vector=[0.1]*1536,\n",
    "    filter=None\n",
    ")\n",
    "\n",
    "RESPONSE:\n",
    "{'matches': [{'id': '263a129b-e46d-4102-a093-379575b45947',\n",
    "              'metadata': {'source': '../examples/data/pg_essay_beyond_smart.txt',\n",
    "                           'text': 'Notes\\n'\n",
    "                                   '\\n'\n",
    "                                   '[1] What wins in conversation depends on '\n",
    "                                   'who with. It ranges from mere '\n",
    "                                   'aggressiveness at the bottom, through '\n",
    "                                   'quick-wittedness in the middle, to '\n",
    "                                   'something closer to actual intelligence at '\n",
    "                                   'the top, though probably always with some '\n",
    "                                   'component of quick-wittedness.'},\n",
    "              'score': -0.0292761475,\n",
    "              'values': [-0.0114761228,\n",
    "                         0.0137850493,\n",
    "                         -0.0456852466]}],\n",
    " 'namespace': ''}\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "for query_result_item in query_response.get('matches',[]):\n",
    "    ids.append(query_result_item['id'])\n",
    "if len(ids) > 0: index.delete(ids=ids, namespace=PINECONE_TEST_NAMESPACE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
