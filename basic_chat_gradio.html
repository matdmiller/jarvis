<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.2.475">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="description" content="A basic gradio chat bot using OpenAI APIâ€™s">

<title>jarvis - basic_chat_gradio</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1.6em;
  vertical-align: middle;
}
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>


<link rel="stylesheet" href="styles.css">
<meta property="og:title" content="jarvis - basic_chat_gradio">
<meta property="og:description" content="A basic gradio chat bot using OpenAI API's">
<meta property="og:site-name" content="jarvis">
<meta name="twitter:title" content="jarvis - basic_chat_gradio">
<meta name="twitter:description" content="A basic gradio chat bot using OpenAI API's">
<meta name="twitter:card" content="summary">
</head>

<body class="nav-sidebar floating nav-fixed">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
    <nav class="navbar navbar-expand-lg navbar-dark ">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container">
    <a class="navbar-brand" href="./index.html">
    <span class="navbar-title">jarvis</span>
    </a>
  </div>
          <div id="quarto-search" class="" title="Search"></div>
      </div> <!-- /container-fluid -->
    </nav>
  <nav class="quarto-secondary-nav" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
    <div class="container-fluid d-flex justify-content-between">
      <h1 class="quarto-secondary-nav-title">basic_chat_gradio</h1>
      <button type="button" class="quarto-btn-toggle btn" aria-label="Show secondary navigation">
        <i class="bi bi-chevron-right"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse sidebar-navigation floating overflow-auto">
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">jarvis</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./core.html" class="sidebar-item-text sidebar-link">core</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./secrets.html" class="sidebar-item-text sidebar-link">secrets</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./basic_chat_gradio.html" class="sidebar-item-text sidebar-link active">basic_chat_gradio</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./python_repl.html" class="sidebar-item-text sidebar-link">python_repl</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./pinecone.html" class="sidebar-item-text sidebar-link">pinecone</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./openai_embeddings.html" class="sidebar-item-text sidebar-link">openai_embeddings</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./chromadb.html" class="sidebar-item-text sidebar-link">chromadb</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./langchain_gradio_streaming.html" class="sidebar-item-text sidebar-link">langchain_gradio_streaming</a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./sqlite_explorer.html" class="sidebar-item-text sidebar-link">SQLite Explorer</a>
  </div>
</li>
    </ul>
    </div>
</nav>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">On this page</h2>
   
  <ul>
  <li><a href="#completion-messages" id="toc-completion-messages" class="nav-link active" data-scroll-target="#completion-messages">Completion Messages</a></li>
  <li><a href="#gradio-interface" id="toc-gradio-interface" class="nav-link" data-scroll-target="#gradio-interface">Gradio Interface</a>
  <ul class="collapse">
  <li><a href="#parse_codeblock" id="toc-parse_codeblock" class="nav-link" data-scroll-target="#parse_codeblock">parse_codeblock</a></li>
  <li><a href="#gradio_chat_history_to_openai_chat_completions_format" id="toc-gradio_chat_history_to_openai_chat_completions_format" class="nav-link" data-scroll-target="#gradio_chat_history_to_openai_chat_completions_format">gradio_chat_history_to_openai_chat_completions_format</a></li>
  <li><a href="#process_user_message" id="toc-process_user_message" class="nav-link" data-scroll-target="#process_user_message">process_user_message</a></li>
  <li><a href="#process_bot_message" id="toc-process_bot_message" class="nav-link" data-scroll-target="#process_bot_message">process_bot_message</a></li>
  </ul></li>
  </ul>
<div class="toc-actions"><div><i class="bi bi-github"></i></div><div class="action-links"><p><a href="https://github.com/matdmiller/jarvis/issues/new" class="toc-action">Report an issue</a></p></div></div></nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title d-none d-lg-block">basic_chat_gradio</h1>
</div>

<div>
  <div class="description">
    A basic gradio chat bot using OpenAI APIâ€™s
  </div>
</div>


<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<!-- WARNING: THIS FILE WAS AUTOGENERATED! DO NOT EDIT! -->
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="co"># from langchain.cache import SQLiteCache</span></span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="co"># import langchain</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="co"># langchain.llm_cache = SQLiteCache(database_path="../.langchain.db")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Setting the default environment API key for the OpenAI API python client.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a>openai.api_key <span class="op">=</span> os.environ[<span class="st">"OPENAI_API_KEY"</span>]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>openai.enable_telemetry</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display">
<pre><code>False</code></pre>
</div>
</div>
<p>List of all OpenAI model listing the root model and release date, sorted by release date with the most recent at the top.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>models <span class="op">=</span> openai.Model.<span class="bu">list</span>()</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> _model <span class="kw">in</span> <span class="bu">sorted</span>(models.data, key<span class="op">=</span><span class="kw">lambda</span> o: o.get(<span class="st">'created'</span>), reverse<span class="op">=</span><span class="va">True</span>):</span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="ss">f"</span><span class="sc">{</span>_model<span class="sc">.</span>get(<span class="st">'id'</span>)<span class="sc">}</span><span class="ss"> - ROOT: </span><span class="sc">{</span>_model<span class="sc">.</span>get(<span class="st">'root'</span>)<span class="sc">}</span><span class="ss"> - CREATED: </span><span class="sc">{</span>datetime<span class="sc">.</span>datetime<span class="sc">.</span>fromtimestamp(_model.get(<span class="st">'created'</span>))<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="co">#models.data</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>gpt-4 - ROOT: gpt-4 - CREATED: 2023-03-12 07:03:22
gpt-4-0314 - ROOT: gpt-4-0314 - CREATED: 2023-03-12 07:03:21
gpt-3.5-turbo-0301 - ROOT: gpt-3.5-turbo-0301 - CREATED: 2023-03-01 05:52:43
gpt-3.5-turbo - ROOT: gpt-3.5-turbo - CREATED: 2023-02-28 18:56:42
whisper-1 - ROOT: whisper-1 - CREATED: 2023-02-27 21:13:04
text-embedding-ada-002 - ROOT: text-embedding-ada-002 - CREATED: 2022-12-16 19:01:39
text-davinci-003 - ROOT: text-davinci-003 - CREATED: 2022-11-28 01:40:35
ada-code-search-text - ROOT: ada-code-search-text - CREATED: 2022-04-28 19:01:50
babbage-search-document - ROOT: babbage-search-document - CREATED: 2022-04-28 19:01:50
curie-similarity - ROOT: curie-similarity - CREATED: 2022-04-28 19:01:50
babbage-code-search-code - ROOT: babbage-code-search-code - CREATED: 2022-04-28 19:01:49
babbage-code-search-text - ROOT: babbage-code-search-text - CREATED: 2022-04-28 19:01:49
davinci-search-document - ROOT: davinci-search-document - CREATED: 2022-04-28 19:01:49
curie-search-query - ROOT: curie-search-query - CREATED: 2022-04-28 19:01:49
text-search-curie-query-001 - ROOT: text-search-curie-query-001 - CREATED: 2022-04-28 19:01:49
text-search-babbage-doc-001 - ROOT: text-search-babbage-doc-001 - CREATED: 2022-04-28 19:01:49
text-search-curie-doc-001 - ROOT: text-search-curie-doc-001 - CREATED: 2022-04-28 19:01:49
babbage-search-query - ROOT: babbage-search-query - CREATED: 2022-04-28 19:01:49
text-search-babbage-query-001 - ROOT: text-search-babbage-query-001 - CREATED: 2022-04-28 19:01:49
davinci-similarity - ROOT: davinci-similarity - CREATED: 2022-04-28 19:01:49
curie-search-document - ROOT: curie-search-document - CREATED: 2022-04-28 19:01:48
code-search-babbage-text-001 - ROOT: code-search-babbage-text-001 - CREATED: 2022-04-28 19:01:47
code-search-babbage-code-001 - ROOT: code-search-babbage-code-001 - CREATED: 2022-04-28 19:01:47
ada-similarity - ROOT: ada-similarity - CREATED: 2022-04-28 19:01:47
code-search-ada-text-001 - ROOT: code-search-ada-text-001 - CREATED: 2022-04-28 19:01:47
text-search-ada-doc-001 - ROOT: text-search-ada-doc-001 - CREATED: 2022-04-28 19:01:47
text-similarity-curie-001 - ROOT: text-similarity-curie-001 - CREATED: 2022-04-28 19:01:47
code-search-ada-code-001 - ROOT: code-search-ada-code-001 - CREATED: 2022-04-28 19:01:47
ada-search-document - ROOT: ada-search-document - CREATED: 2022-04-28 19:01:47
text-similarity-babbage-001 - ROOT: text-similarity-babbage-001 - CREATED: 2022-04-28 19:01:45
babbage-similarity - ROOT: babbage-similarity - CREATED: 2022-04-28 19:01:45
text-similarity-ada-001 - ROOT: text-similarity-ada-001 - CREATED: 2022-04-28 19:01:45
ada-code-search-code - ROOT: ada-code-search-code - CREATED: 2022-04-28 19:01:45
text-search-ada-query-001 - ROOT: text-search-ada-query-001 - CREATED: 2022-04-28 19:01:45
ada-search-query - ROOT: ada-search-query - CREATED: 2022-04-28 19:01:45
text-search-davinci-query-001 - ROOT: text-search-davinci-query-001 - CREATED: 2022-04-28 19:01:45
davinci-search-query - ROOT: davinci-search-query - CREATED: 2022-04-28 19:01:45
text-search-davinci-doc-001 - ROOT: text-search-davinci-doc-001 - CREATED: 2022-04-28 19:01:45
text-similarity-davinci-001 - ROOT: text-similarity-davinci-001 - CREATED: 2022-04-28 19:01:45
code-davinci-edit-001 - ROOT: code-davinci-edit-001 - CREATED: 2022-04-13 20:08:04
text-davinci-002 - ROOT: text-davinci-002 - CREATED: 2022-04-13 20:08:04
text-davinci-edit-001 - ROOT: text-davinci-edit-001 - CREATED: 2022-04-13 00:19:39
text-curie-001 - ROOT: text-curie-001 - CREATED: 2022-04-07 20:40:43
text-babbage-001 - ROOT: text-babbage-001 - CREATED: 2022-04-07 20:40:43
text-davinci-001 - ROOT: text-davinci-001 - CREATED: 2022-04-07 20:40:42
text-ada-001 - ROOT: text-ada-001 - CREATED: 2022-04-07 20:40:42
curie-instruct-beta - ROOT: curie-instruct-beta - CREATED: 2022-04-07 20:40:42
davinci-instruct-beta - ROOT: davinci-instruct-beta - CREATED: 2022-04-07 20:40:42
davinci - ROOT: davinci - CREATED: 2022-04-07 19:31:14
curie - ROOT: curie - CREATED: 2022-04-07 19:31:14
babbage - ROOT: babbage - CREATED: 2022-04-07 19:07:29
ada - ROOT: ada - CREATED: 2022-04-07 18:51:31
text-babbage:001 - ROOT: text-babbage:001 - CREATED: 2022-01-12 20:12:50
text-curie:001 - ROOT: text-curie:001 - CREATED: 2022-01-12 02:37:27
text-ada:001 - ROOT: text-ada:001 - CREATED: 2022-01-12 01:06:48
text-davinci:001 - ROOT: text-davinci:001 - CREATED: 2022-01-11 23:32:46
davinci-instruct-beta:2.0.0 - ROOT: davinci-instruct-beta:2.0.0 - CREATED: 2021-08-20 23:25:14
davinci-if:3.0.0 - ROOT: davinci-if:3.0.0 - CREATED: 2021-08-20 22:21:10
if-davinci:3.0.0 - ROOT: if-davinci:3.0.0 - CREATED: 2021-08-20 00:52:35
if-davinci-v2 - ROOT: if-davinci-v2 - CREATED: 2021-01-15 21:26:30
if-curie-v2 - ROOT: if-curie-v2 - CREATED: 2021-01-15 21:26:08
davinci:2020-05-03 - ROOT: davinci:2020-05-03 - CREATED: 2020-12-10 22:42:43
curie:2020-05-03 - ROOT: curie:2020-05-03 - CREATED: 2020-12-10 20:38:45
babbage:2020-05-03 - ROOT: babbage:2020-05-03 - CREATED: 2020-12-10 20:36:51
ada:2020-05-03 - ROOT: ada:2020-05-03 - CREATED: 2020-12-10 20:20:25
cushman:2020-05-03 - ROOT: cushman:2020-05-03 - CREATED: 2020-05-28 00:18:30</code></pre>
</div>
</div>
<section id="completion-messages" class="level2">
<h2 class="anchored" data-anchor-id="completion-messages">Completion Messages</h2>
<p>An example set of chat messages formatted for chat completion. Example from https://platform.openai.com/docs/guides/chat/introduction:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>openai.ChatCompletion.create(</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  model<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>,</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  messages<span class="op">=</span>[</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"system"</span>, <span class="st">"content"</span>: <span class="st">"You are a helpful assistant."</span>},</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Who won the world series in 2020?"</span>},</span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"assistant"</span>, <span class="st">"content"</span>: <span class="st">"The Los Angeles Dodgers won the World Series in 2020."</span>},</span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>        {<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Where was it played?"</span>}</span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>With corresponding example response (non-streaming). Example from https://platform.openai.com/docs/api-reference/chat/create</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>{</span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>  <span class="st">"id"</span>: <span class="st">"chatcmpl-123"</span>,</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a>  <span class="st">"object"</span>: <span class="st">"chat.completion"</span>,</span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>  <span class="st">"created"</span>: <span class="dv">1677652288</span>,</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span class="st">"choices"</span>: [{</span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">"index"</span>: <span class="dv">0</span>,</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">"message"</span>: {</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>      <span class="st">"role"</span>: <span class="st">"assistant"</span>,</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>      <span class="st">"content"</span>: <span class="st">"</span><span class="ch">\n\n</span><span class="st">Hello there, how may I assist you today?"</span>,</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a>    },</span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">"finish_reason"</span>: <span class="st">"stop"</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  }],</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>  <span class="st">"usage"</span>: {</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    <span class="st">"prompt_tokens"</span>: <span class="dv">9</span>,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    <span class="st">"completion_tokens"</span>: <span class="dv">12</span>,</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    <span class="st">"total_tokens"</span>: <span class="dv">21</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>}</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<p>And finally an example streaming implementation https://huggingface.co/spaces/ysharma/ChatGPTwithAPI/blob/main/app.py</p>
<p>Below is a simple example of using Chat completions</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>completion <span class="op">=</span> openai.ChatCompletion.create(model<span class="op">=</span><span class="st">"gpt-3.5-turbo"</span>, messages<span class="op">=</span>[{<span class="st">"role"</span>: <span class="st">"user"</span>, <span class="st">"content"</span>: <span class="st">"Hello world!"</span>}])</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(completion.choices[<span class="dv">0</span>].message.content)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Hello there! How may I assist you today?</code></pre>
</div>
</div>
<p>And here is a streaming example</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span class="co">#streaming completion</span></span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>    model<span class="op">=</span><span class="st">'gpt-3.5-turbo'</span>,</span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    messages<span class="op">=</span>[</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        {<span class="st">'role'</span>: <span class="st">'user'</span>, <span class="st">'content'</span>: <span class="st">"write a short, single verse, poem about math"</span>}</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>    ],</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>    temperature<span class="op">=</span><span class="dv">0</span>,</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>    stream<span class="op">=</span><span class="va">True</span>  <span class="co"># this time, we set stream=True</span></span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a><span class="cf">for</span> idx, chunk <span class="kw">in</span> <span class="bu">enumerate</span>(response):</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> idx <span class="op">==</span> <span class="dv">1</span>: <span class="bu">print</span>(chunk)</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(chunk.get(<span class="st">'choices'</span>,[{}])[<span class="dv">0</span>].get(<span class="st">'delta'</span>,{}).get(<span class="st">'content'</span>,<span class="st">''</span>),end<span class="op">=</span><span class="st">''</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>{
  "choices": [
    {
      "delta": {
        "content": "Numbers"
      },
      "finish_reason": null,
      "index": 0
    }
  ],
  "created": 1681622446,
  "id": "chatcmpl-75p6caNCtr22uffycUOdGBAp4j8Nw",
  "model": "gpt-3.5-turbo-0301",
  "object": "chat.completion.chunk"
}
Numbers dance in perfect time,
Equations flow like sweetest rhyme,
Mathematics, pure and true,
A world of wonder, ever anew.</code></pre>
</div>
</div>
</section>
<section id="gradio-interface" class="level2">
<h2 class="anchored" data-anchor-id="gradio-interface">Gradio Interface</h2>
<p><a href="https://matdmiller.github.io/jarvis/basic_chat_gradio.html#parse_codeblock"><code>parse_codeblock</code></a> is a temporary fix for gradio displaying code correctly inside of triple backticks.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> parse_codeblock(text):</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Fixes how code blocks are displayed in the gradio chat window. </span></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a><span class="co">    Ref: https://github.com/gradio-app/gradio/issues/3531"""</span></span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    lines <span class="op">=</span> text.split(<span class="st">"</span><span class="ch">\n</span><span class="st">"</span>)</span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> i, line <span class="kw">in</span> <span class="bu">enumerate</span>(lines):</span>
<span id="cb14-6"><a href="#cb14-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> <span class="st">"```"</span> <span class="kw">in</span> line:</span>
<span id="cb14-7"><a href="#cb14-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> line <span class="op">!=</span> <span class="st">"```"</span>:</span>
<span id="cb14-8"><a href="#cb14-8" aria-hidden="true" tabindex="-1"></a>                lines[i] <span class="op">=</span> <span class="ss">f'&lt;pre&gt;&lt;code class="</span><span class="sc">{</span>lines[i][<span class="dv">3</span>:]<span class="sc">}</span><span class="ss">"&gt;'</span></span>
<span id="cb14-9"><a href="#cb14-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">else</span>:</span>
<span id="cb14-10"><a href="#cb14-10" aria-hidden="true" tabindex="-1"></a>                lines[i] <span class="op">=</span> <span class="st">'&lt;/code&gt;&lt;/pre&gt;'</span></span>
<span id="cb14-11"><a href="#cb14-11" aria-hidden="true" tabindex="-1"></a>        <span class="cf">else</span>:</span>
<span id="cb14-12"><a href="#cb14-12" aria-hidden="true" tabindex="-1"></a>            <span class="cf">if</span> i <span class="op">&gt;</span> <span class="dv">0</span>:</span>
<span id="cb14-13"><a href="#cb14-13" aria-hidden="true" tabindex="-1"></a>                lines[i] <span class="op">=</span> <span class="st">"&lt;br/&gt;"</span> <span class="op">+</span> line.replace(<span class="st">"&lt;"</span>, <span class="st">"&amp;lt;"</span>).replace(<span class="st">"&gt;"</span>, <span class="st">"&amp;gt;"</span>)</span>
<span id="cb14-14"><a href="#cb14-14" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">""</span>.join(lines)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/matdmiller/jarvis/blob/main/jarvis/basic_chat_gradio.py#L19" target="_blank" style="float:right; font-size:smaller">source</a></p>
<section id="parse_codeblock" class="level3">
<h3 class="anchored" data-anchor-id="parse_codeblock">parse_codeblock</h3>
<blockquote class="blockquote">
<pre><code> parse_codeblock (text)</code></pre>
</blockquote>
<p>Fixes how code blocks are displayed in the gradio chat window. Ref: https://github.com/gradio-app/gradio/issues/3531</p>
<p>TODO: - Add tiktoken token counter for streaming api. https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb - Add running total calculator to track tokens and $.</p>
<div class="cell">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> gradio_chat_history_to_openai_chat_completions_format(</span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a>    history:<span class="bu">list</span>[<span class="bu">list</span>[<span class="bu">dict</span>]] <span class="co">#Gradio chat history.</span></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a>)<span class="op">-&gt;</span><span class="bu">list</span>[<span class="bu">dict</span>]:</span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Converts gradio chat history to OpenAI messages completions format."""</span></span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    chat_formatted_list <span class="op">=</span> []</span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span class="cf">for</span> message_pair <span class="kw">in</span> history:</span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>        chat_formatted_list.append({<span class="st">'role'</span>:<span class="st">'user'</span>, <span class="st">'content'</span>: message_pair[<span class="dv">0</span>]})</span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a>        <span class="cf">if</span> message_pair[<span class="dv">1</span>] <span class="kw">is</span> <span class="kw">not</span> <span class="va">None</span>:</span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>            chat_formatted_list.append({<span class="st">'role'</span>:<span class="st">'assistant'</span>, <span class="st">'content'</span>: message_pair[<span class="dv">1</span>]})</span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> chat_formatted_list</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/matdmiller/jarvis/blob/main/jarvis/basic_chat_gradio.py#L35" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="gradio_chat_history_to_openai_chat_completions_format" class="level3">
<h3 class="anchored" data-anchor-id="gradio_chat_history_to_openai_chat_completions_format">gradio_chat_history_to_openai_chat_completions_format</h3>
<blockquote class="blockquote">
<pre><code> gradio_chat_history_to_openai_chat_completions_format
                                                        (history:list[list
                                                        [dict]])</code></pre>
</blockquote>
<p>Converts gradio chat history to OpenAI messages completions format.</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>history</td>
<td>list</td>
<td>Gradio chat history.</td>
</tr>
<tr class="even">
<td><strong>Returns</strong></td>
<td><strong>list</strong></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_user_message(</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>    user_message:<span class="bu">str</span>, <span class="co">#Most recent message from user.</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    history:<span class="bu">list</span>[<span class="bu">list</span>[<span class="bu">str</span>]] <span class="co">#Message history from gradio.Chatbot instance.</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>)<span class="op">-&gt;</span><span class="bu">tuple</span>[<span class="bu">str</span>,<span class="bu">list</span>[<span class="bu">list</span>[<span class="bu">str</span>]]]:</span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Add user message to 'history' and clear message textbox."""</span></span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span class="bu">print</span>(<span class="st">'process_user_message'</span>,user_message,history)</span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>    <span class="co"># if history is None: history = []</span></span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a>    <span class="cf">return</span> <span class="st">""</span>, history <span class="op">+</span> [[user_message, <span class="va">None</span>]]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/matdmiller/jarvis/blob/main/jarvis/basic_chat_gradio.py#L47" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="process_user_message" class="level3">
<h3 class="anchored" data-anchor-id="process_user_message">process_user_message</h3>
<blockquote class="blockquote">
<pre><code> process_user_message (user_message:str, history:list[list[str]])</code></pre>
</blockquote>
<p>Add user message to â€˜historyâ€™ and clear message textbox.</p>
<table class="table">
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>user_message</td>
<td>str</td>
<td>Most recent message from user.</td>
</tr>
<tr class="even">
<td>history</td>
<td>list</td>
<td>Message history from gradio.Chatbot instance.</td>
</tr>
<tr class="odd">
<td><strong>Returns</strong></td>
<td><strong>tuple</strong></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="kw">def</span> process_bot_message(</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a>    history:<span class="bu">list</span>[<span class="bu">list</span>[<span class="bu">str</span>]], <span class="co">#Message history from gradio.Chatbot instance.</span></span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a>    system_msg:<span class="bu">str</span>, <span class="co">#Most recent message from user.</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a>    selected_model:<span class="bu">str</span>, <span class="co">#Selected OpenAI model for chat completion.</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>    temperature:<span class="bu">float</span><span class="op">=</span><span class="fl">0.</span>, <span class="co">#How deterministic the model results are.  See OpenAI docs.</span></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    stream:<span class="bu">bool</span><span class="op">=</span><span class="va">True</span>, <span class="co">#Whether or not to stream the results or return all at once when the model has finished its response.</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>)<span class="op">-&gt;</span><span class="bu">list</span>[<span class="bu">list</span>[<span class="bu">str</span>]]:</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>    <span class="co">"""Send chat history with most recent user message to the chat completions API."""</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    stream_results <span class="op">=</span> <span class="st">''</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    history[<span class="op">-</span><span class="dv">1</span>][<span class="dv">1</span>] <span class="op">=</span> <span class="st">''</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span class="co"># try:</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    response <span class="op">=</span> openai.ChatCompletion.create(</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        model<span class="op">=</span>selected_model,</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        messages<span class="op">=</span>[{<span class="st">'role'</span>:<span class="st">'system'</span>, <span class="st">'content'</span>: system_msg}] <span class="op">+</span> gradio_chat_history_to_openai_chat_completions_format(history),</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>        temperature<span class="op">=</span>temperature,</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>        stream<span class="op">=</span>stream  <span class="co"># this time, we set stream=True</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    <span class="cf">if</span> stream:</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>        <span class="cf">for</span> chunk <span class="kw">in</span> response:</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>            model_results.append(model_results)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print(chunk)</span></span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>            <span class="co"># print(chunk.get('choices',[{}])[0].get('delta',{}).get('content',''),end='')</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>            stream_results <span class="op">+=</span> chunk.get(<span class="st">'choices'</span>,[{}])[<span class="dv">0</span>].get(<span class="st">'delta'</span>,{}).get(<span class="st">'content'</span>,<span class="st">''</span>)</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a>            <span class="co"># history[-1][1] = parse_codeblock(stream_results) #removed because gradio properly formats code blocks now</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>            history[<span class="op">-</span><span class="dv">1</span>][<span class="dv">1</span>] <span class="op">=</span> stream_results</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>            <span class="cf">yield</span> history</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    <span class="cf">else</span>:</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(response)</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(response.get('choices',[{}])[0].get('message',{}).get('content',''))</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(parse_codeblock(response.get('choices',[{}])[0].get('message',{}).get('content','')))</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        <span class="co"># history[-1][1] = parse_codeblock(response.get('choices',[{}])[0].get('message',{}).get('content','')) #gradio fixed code blocks natively</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>        history[<span class="op">-</span><span class="dv">1</span>][<span class="dv">1</span>] <span class="op">=</span> response.get(<span class="st">'choices'</span>,[{}])[<span class="dv">0</span>].get(<span class="st">'message'</span>,{}).get(<span class="st">'content'</span>,<span class="st">''</span>)</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>        <span class="co"># print(history)</span></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>        <span class="cf">yield</span> history</span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    <span class="co"># except:</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     pass</span></span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>    <span class="co">#     # print(history, system_msg, [{'role':'system', 'content': system_msg}] + history_to_chatgpt_format(history))</span></span>
<span id="cb20-38"><a href="#cb20-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-39"><a href="#cb20-39" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(response)</span></span>
<span id="cb20-40"><a href="#cb20-40" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(stream_results)</span></span>
<span id="cb20-41"><a href="#cb20-41" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(parse_codeblock(stream_results))</span></span>
<span id="cb20-42"><a href="#cb20-42" aria-hidden="true" tabindex="-1"></a>    <span class="co"># print(history[-1][1])</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
<p><a href="https://github.com/matdmiller/jarvis/blob/main/jarvis/basic_chat_gradio.py#L57" target="_blank" style="float:right; font-size:smaller">source</a></p>
</section>
<section id="process_bot_message" class="level3">
<h3 class="anchored" data-anchor-id="process_bot_message">process_bot_message</h3>
<blockquote class="blockquote">
<pre><code> process_bot_message (history:list[list[str]], system_msg:str,
                      selected_model:str, temperature:float=0.0,
                      stream:bool=True)</code></pre>
</blockquote>
<p>Send chat history with most recent user message to the chat completions API.</p>
<table class="table">
<colgroup>
<col style="width: 6%">
<col style="width: 25%">
<col style="width: 34%">
<col style="width: 34%">
</colgroup>
<thead>
<tr class="header">
<th></th>
<th><strong>Type</strong></th>
<th><strong>Default</strong></th>
<th><strong>Details</strong></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>history</td>
<td>list</td>
<td></td>
<td>Message history from gradio.Chatbot instance.</td>
</tr>
<tr class="even">
<td>system_msg</td>
<td>str</td>
<td></td>
<td>Most recent message from user.</td>
</tr>
<tr class="odd">
<td>selected_model</td>
<td>str</td>
<td></td>
<td>Selected OpenAI model for chat completion.</td>
</tr>
<tr class="even">
<td>temperature</td>
<td>float</td>
<td>0.0</td>
<td>How deterministic the model results are. See OpenAI docs.</td>
</tr>
<tr class="odd">
<td>stream</td>
<td>bool</td>
<td>True</td>
<td>Whether or not to stream the results or return all at once when the model has finished its response.</td>
</tr>
<tr class="even">
<td><strong>Returns</strong></td>
<td><strong>list</strong></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a>model_results <span class="op">=</span> []</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a><span class="cf">with</span> gr.Blocks(title<span class="op">=</span><span class="st">'Jarvis - My ChatGPT'</span>) <span class="im">as</span> demo:</span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> gr.Tab(label<span class="op">=</span><span class="st">'Chat'</span>):</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>        chatbot <span class="op">=</span> gr.Chatbot()</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>        <span class="co"># chatbot.change(fn=lambda: None, scroll_to_output=True) #This also doesn't work. Autoscroll when chatbot in tab is known issue.</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>        <span class="cf">with</span> gr.Row():</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> gr.Column(scale<span class="op">=</span><span class="dv">10</span>):</span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>                msg <span class="op">=</span> gr.Textbox()</span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>            <span class="cf">with</span> gr.Column(scale<span class="op">=</span><span class="dv">1</span>):</span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>                clear <span class="op">=</span> gr.Button(<span class="st">"Clear"</span>)</span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>                submit <span class="op">=</span> gr.Button(<span class="st">"Send"</span>)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>    <span class="cf">with</span> gr.Tab(label<span class="op">=</span><span class="st">'Settings'</span>):</span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a>        system_msg <span class="op">=</span> gr.Textbox(value<span class="op">=</span><span class="st">'You are a helpful assistant.'</span>, info<span class="op">=</span><span class="st">'This is the system message for OpenAI Chat APIs.'</span>)</span>
<span id="cb22-14"><a href="#cb22-14" aria-hidden="true" tabindex="-1"></a>        model_selection <span class="op">=</span> gr.Dropdown(choices<span class="op">=</span>[<span class="st">'gpt-3.5-turbo'</span>,<span class="st">'gpt-4'</span>],value<span class="op">=</span><span class="st">'gpt-3.5-turbo'</span>,label<span class="op">=</span><span class="st">'Select model: '</span>)</span>
<span id="cb22-15"><a href="#cb22-15" aria-hidden="true" tabindex="-1"></a>        temperature <span class="op">=</span> gr.Slider(maximum<span class="op">=</span><span class="fl">2.</span>, value<span class="op">=</span><span class="fl">0.</span>, step<span class="op">=</span><span class="fl">.1</span>, label<span class="op">=</span><span class="st">'Temperature'</span>, info<span class="op">=</span><span class="st">'What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic.'</span>,)</span>
<span id="cb22-16"><a href="#cb22-16" aria-hidden="true" tabindex="-1"></a>        stream_results <span class="op">=</span> gr.Checkbox(value<span class="op">=</span><span class="va">True</span>, label<span class="op">=</span><span class="st">'Stream Results'</span>, )</span>
<span id="cb22-17"><a href="#cb22-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-18"><a href="#cb22-18" aria-hidden="true" tabindex="-1"></a>    submit0_kwargs <span class="op">=</span> <span class="bu">dict</span>(fn<span class="op">=</span>process_user_message, inputs<span class="op">=</span>[msg, chatbot], outputs<span class="op">=</span>[msg, chatbot])</span>
<span id="cb22-19"><a href="#cb22-19" aria-hidden="true" tabindex="-1"></a>    submit1_kwargs <span class="op">=</span> <span class="bu">dict</span>(fn<span class="op">=</span>process_bot_message, inputs<span class="op">=</span>[chatbot, system_msg, model_selection, temperature, stream_results], outputs<span class="op">=</span>chatbot)</span>
<span id="cb22-20"><a href="#cb22-20" aria-hidden="true" tabindex="-1"></a>    msg.submit(<span class="op">**</span>submit0_kwargs).then(<span class="op">**</span>submit1_kwargs)</span>
<span id="cb22-21"><a href="#cb22-21" aria-hidden="true" tabindex="-1"></a>    clear.click(fn<span class="op">=</span><span class="kw">lambda</span>: (<span class="va">None</span>, <span class="va">None</span>), inputs<span class="op">=</span><span class="va">None</span>, outputs<span class="op">=</span>[chatbot,msg], queue<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb22-22"><a href="#cb22-22" aria-hidden="true" tabindex="-1"></a>    submit.click(<span class="op">**</span>submit0_kwargs).then(<span class="op">**</span>submit1_kwargs)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a>demo.queue(concurrency_count<span class="op">=</span><span class="dv">2</span>)</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>demo.launch(server_name<span class="op">=</span><span class="st">'0.0.0.0'</span>)<span class="co">#,server_port=7860)</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a>demo.close()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>Closing server running on port: 7862</code></pre>
</div>
</div>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>gr.close_all()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>


</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "î§‹";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    target: function(trigger) {
      return trigger.previousElementSibling;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>